{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dc0ec06",
   "metadata": {},
   "source": [
    "# `AA Workshop 10` — Coding Challenge\n",
    "\n",
    "Complete the tasks below to practice implementing classification modeling from `W10_Neural_Networks.ipynb`.\n",
    "\n",
    "Guidelines:\n",
    "- Work in order. Run each cell after editing with Shift+Enter.\n",
    "- Keep answers short; focus on making things work.\n",
    "- If a step fails, read the error and fix it.\n",
    "\n",
    "By the end you will have exercised:\n",
    "- defining an architecture of a NN\n",
    "- implementing a NN for a multi-class classification problem\n",
    "- evaluating performance throughout the fitting process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fdc70a",
   "metadata": {},
   "source": [
    "## Task 1 - Employing a Neural Network to Classify Breast Cancer Cells\n",
    "\n",
    "In the workshop notebook, you learned how to use the keras framework for both classifcation and regression prediction. The classification example we used was for a binary output (cancer cells being benign or malignant). Let's see how we can employ neural networks for multi-class classification. Do the following:\n",
    "\n",
    "1. Use the `../data/iris.csv` dataset and preproccess it as usual.\n",
    "2. Think of an architecture you would employ to enable multi-class classification. You can get some inspiration [here](https://keras.io/guides/sequential_model/).\n",
    "3. Implement a pipeline that consists of the following:\n",
    "    1. train the model on training data\n",
    "    2. evaluate and visualize loss on a training and validation set throughout the fitting of the network\n",
    "4. Use that pipeline to test different architectures / hyperparameters\n",
    "5. Report final performance on the test set\n",
    "6. Think about the model complexity vs. performance tradeoff - is the NN the best overall model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a287a9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "from keras.utils import to_categorical\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29d985a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width Species\n",
       "0       1           5.1          3.5           1.4          0.2  setosa\n",
       "1       2           4.9          3.0           1.4          0.2  setosa\n",
       "2       3           4.7          3.2           1.3          0.2  setosa\n",
       "3       4           4.6          3.1           1.5          0.2  setosa\n",
       "4       5           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and preprocess data\n",
    "iris = pd.read_csv('../data/iris.csv')\n",
    "iris.dropna(inplace=True)\n",
    "\n",
    "X = iris[['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']]\n",
    "y = iris['Species']\n",
    "\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b67e9b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorical target vector\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5130a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de56a6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "222e042f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create NN model using Keras Sequential API\n",
    "## initialize\n",
    "model = Sequential()\n",
    "\n",
    "## add input layer\n",
    "model.add(Input((4,)))\n",
    "\n",
    "## add first hidden layer\n",
    "model.add(Dense(64, activation=None)) # linear combination\n",
    "# model.add(Dropout(rate = 0.1)) # optional: dropout\n",
    "\n",
    "## add second hidden layer\n",
    "model.add(Dense(32, activation='relu')) # Rectified Linear Unit activation function\n",
    "# model.add(Dropout(rate = 0.1)) # optional: dropout\n",
    "\n",
    "## add output layer with one node per output class (i.e. for each iris species)\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "## compile\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3daa2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# train and evaluate\n",
    "def train_and_evaluate(model, visualize=False):\n",
    "    history = model.fit(X_train, y_train, batch_size = 20, epochs = 20, validation_split=0.3)\n",
    "    if visualize:\n",
    "        pd.DataFrame(history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b95e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3333 - loss: 1.4345 - val_accuracy: 0.3824 - val_loss: 1.1692\n",
      "Epoch 2/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3333 - loss: 1.1958 - val_accuracy: 0.3824 - val_loss: 1.0473\n",
      "Epoch 3/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.3590 - loss: 1.0167 - val_accuracy: 0.5294 - val_loss: 0.9487\n",
      "Epoch 4/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6538 - loss: 0.8667 - val_accuracy: 0.7353 - val_loss: 0.8622\n",
      "Epoch 5/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7564 - loss: 0.7538 - val_accuracy: 0.7941 - val_loss: 0.7849\n",
      "Epoch 6/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7949 - loss: 0.6666 - val_accuracy: 0.7941 - val_loss: 0.7195\n",
      "Epoch 7/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8205 - loss: 0.5940 - val_accuracy: 0.7941 - val_loss: 0.6660\n",
      "Epoch 8/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8462 - loss: 0.5416 - val_accuracy: 0.8235 - val_loss: 0.6176\n",
      "Epoch 9/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8590 - loss: 0.4983 - val_accuracy: 0.8529 - val_loss: 0.5753\n",
      "Epoch 10/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8590 - loss: 0.4635 - val_accuracy: 0.8824 - val_loss: 0.5375\n",
      "Epoch 11/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8333 - loss: 0.4343 - val_accuracy: 0.8824 - val_loss: 0.5049\n",
      "Epoch 12/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8462 - loss: 0.4091 - val_accuracy: 0.8529 - val_loss: 0.4757\n",
      "Epoch 13/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8590 - loss: 0.3871 - val_accuracy: 0.8529 - val_loss: 0.4508\n",
      "Epoch 14/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8718 - loss: 0.3689 - val_accuracy: 0.8529 - val_loss: 0.4295\n",
      "Epoch 15/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8718 - loss: 0.3532 - val_accuracy: 0.8529 - val_loss: 0.4118\n",
      "Epoch 16/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8718 - loss: 0.3392 - val_accuracy: 0.8529 - val_loss: 0.3970\n",
      "Epoch 17/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.3269 - val_accuracy: 0.8529 - val_loss: 0.3844\n",
      "Epoch 18/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.3158 - val_accuracy: 0.8529 - val_loss: 0.3737\n",
      "Epoch 19/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.3063 - val_accuracy: 0.8235 - val_loss: 0.3637\n",
      "Epoch 20/20\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8718 - loss: 0.2965 - val_accuracy: 0.8235 - val_loss: 0.3556\n"
     ]
    }
   ],
   "source": [
    "# execute\n",
    "train_and_evaluate(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4702737d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7857 - loss: 0.3966\n",
      "Test Set Accuracy: 0.7857\n"
     ]
    }
   ],
   "source": [
    "# evaluate performance on test set\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Set Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd36f1",
   "metadata": {},
   "source": [
    "**IMPORTANT**: Remember that the dataset is (before filtering out NaN) just 50 records of every class (species), so it is a really small dataset and there is really no reason to opt for a neural network here! Indeed, these results can be easily achieved with a SVM or Logistic Regression.\n",
    "\n",
    "This is an important lesson: even though this small NN is fast to build and fit, it is\n",
    "1. inefficient to use a large network for the task\n",
    "1. unnecessary to introduce an opaque method, where we have no idea about things like feature importance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AA_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
